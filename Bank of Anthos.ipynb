{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86075d54-da69-4199-86e1-6f6a45826c26",
   "metadata": {},
   "source": [
    "# Welcome to our playground!\n",
    "\n",
    "It's wonderful to be here\n",
    "It's certainly a thrill\n",
    "You're such a lovely audience\n",
    "We'd like to take you home with us\n",
    "We'd love to take you home\n",
    "\n",
    "## Now let's first see if we can connect to the bank!\n",
    "\n",
    "To do so we need to install some packages and set up the sql extension for Jupyter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "94ef1545-a6a8-4a67-ba41-a0355fce877e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ipython-sql in /opt/conda/lib/python3.10/site-packages (0.5.0)\n",
      "Requirement already satisfied: prettytable in /opt/conda/lib/python3.10/site-packages (from ipython-sql) (3.9.0)\n",
      "Requirement already satisfied: ipython in /opt/conda/lib/python3.10/site-packages (from ipython-sql) (8.17.2)\n",
      "Requirement already satisfied: sqlalchemy>=2.0 in /opt/conda/lib/python3.10/site-packages (from ipython-sql) (2.0.23)\n",
      "Requirement already satisfied: sqlparse in /opt/conda/lib/python3.10/site-packages (from ipython-sql) (0.4.4)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from ipython-sql) (1.16.0)\n",
      "Requirement already satisfied: ipython-genutils in /opt/conda/lib/python3.10/site-packages (from ipython-sql) (0.2.0)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /opt/conda/lib/python3.10/site-packages (from sqlalchemy>=2.0->ipython-sql) (4.8.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from sqlalchemy>=2.0->ipython-sql) (3.0.1)\n",
      "Requirement already satisfied: decorator in /opt/conda/lib/python3.10/site-packages (from ipython->ipython-sql) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/conda/lib/python3.10/site-packages (from ipython->ipython-sql) (0.19.1)\n",
      "Requirement already satisfied: matplotlib-inline in /opt/conda/lib/python3.10/site-packages (from ipython->ipython-sql) (0.1.6)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in /opt/conda/lib/python3.10/site-packages (from ipython->ipython-sql) (3.0.39)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /opt/conda/lib/python3.10/site-packages (from ipython->ipython-sql) (2.16.1)\n",
      "Requirement already satisfied: stack-data in /opt/conda/lib/python3.10/site-packages (from ipython->ipython-sql) (0.6.2)\n",
      "Requirement already satisfied: traitlets>=5 in /opt/conda/lib/python3.10/site-packages (from ipython->ipython-sql) (5.13.0)\n",
      "Requirement already satisfied: exceptiongroup in /opt/conda/lib/python3.10/site-packages (from ipython->ipython-sql) (1.1.3)\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.10/site-packages (from ipython->ipython-sql) (4.8.0)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.10/site-packages (from prettytable->ipython-sql) (0.2.9)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /opt/conda/lib/python3.10/site-packages (from jedi>=0.16->ipython->ipython-sql) (0.8.3)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.10/site-packages (from pexpect>4.3->ipython->ipython-sql) (0.7.0)\n",
      "Requirement already satisfied: executing>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from stack-data->ipython->ipython-sql) (2.0.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /opt/conda/lib/python3.10/site-packages (from stack-data->ipython->ipython-sql) (2.4.1)\n",
      "Requirement already satisfied: pure-eval in /opt/conda/lib/python3.10/site-packages (from stack-data->ipython->ipython-sql) (0.2.2)\n",
      "Requirement already satisfied: sqlalchemy in /opt/conda/lib/python3.10/site-packages (2.0.23)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /opt/conda/lib/python3.10/site-packages (from sqlalchemy) (4.8.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from sqlalchemy) (3.0.1)\n",
      "Requirement already satisfied: psycopg2-binary in /opt/conda/lib/python3.10/site-packages (2.9.9)\n"
     ]
    }
   ],
   "source": [
    "# Installing some python packages to talk SQLd\n",
    "! pip install ipython-sql\n",
    "! pip install sqlalchemy\n",
    "! pip install psycopg2-binary\n",
    "\n",
    "PROJECT_ID='qwiklabs-gcp-02-dc8599e6d4b0' # You can find this in the Google Cloud Console on the home page or dashboard!\n",
    "REGION = 'europe-west4'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1222875d-741a-48cd-a155-c64d9fda03e4",
   "metadata": {
    "tags": []
   },
   "source": [
    "We can jump right into it now - adjust the following cell with the password you created for the postgres user!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41893fa4-08cd-4759-98ed-b3caf854d188",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%sql postgresql://postgres:kcg6a2jg@192.168.142.72:5432/postgres"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66bf227e-0c87-465c-8635-3b813620a273",
   "metadata": {},
   "source": [
    "No news is good news! But to be sure, let's run a query:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4c922c-f119-4200-9b2f-a6405e4ed7be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%sql SELECT * FROM pg_catalog.pg_user"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4abac14c-8662-48e1-88c1-1ff850a009c6",
   "metadata": {},
   "source": [
    "If all went according to plan you will see a table with the results of the SQL query. Feel free to play around with this and query other stuff if you want!\n",
    "\n",
    "## So we can connect to the data, but where is the AI goodness? \n",
    "\n",
    "Right here! But we will start with something simple - let's see if we can predict the next transaction for a certain user! Let's make a dataset out of the transactions database!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a17d7a-816b-43d6-9078-99b7e2c6261d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import SQLAlchemy & Pandas\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "# Define the engine to use\n",
    "engine = create_engine(\"postgresql://postgres:kcg6a2jg@192.168.142.72:5432/transactions-db\")\n",
    "table_name = 'transactions'\n",
    "\n",
    "# Capture the table into a dataframe!\n",
    "\n",
    "table_df = pd.read_sql_table(\n",
    "    table_name,\n",
    "    con=engine\n",
    ")\n",
    "# And store the dataframe as a csv file\n",
    "\n",
    "test_df = table_df.iloc[:10,:]\n",
    "train_df = table_df.iloc[10:,:]\n",
    "\n",
    "test_df.to_csv(\"test_transactions.csv\")\n",
    "train_df.to_csv(\"train_transactions.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb71c5c-50e3-4f3e-8589-fcd9ffcf4548",
   "metadata": {},
   "source": [
    "## AutoGluon\n",
    "\n",
    "Like we mentioned we are starting with something small, using Autogluon. Autogluon will allow you to easily train a model based on a small amount of data (we have only 66 transactions unless you went crazy and added a lot more previously..)\n",
    "\n",
    "We've split the transactions from our table into test and training data and will now start to train a model! The model we are training will be used to predict how much money (amount) will be moved around in the next transaction,\n",
    "based on the other characteristics of the transaction. Isn't that exciting? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d94edd-c15e-4cfb-9c59-50b6679dcf92",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Install and Import autogluon\n",
    "! pip install autogluon\n",
    "from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "\n",
    "train_data = TabularDataset('train_transactions.csv')\n",
    "predictor = TabularPredictor(label='amount').fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88c4240-a73a-4b10-9a0e-af87299c4b6c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Optional - evaluate the model\n",
    "test_data = TabularDataset('test_transactions.csv')\n",
    "predictor.evaluate(test_data, silent=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c00f1770-59a9-4f55-83ba-cf46d28b18f8",
   "metadata": {
    "tags": []
   },
   "source": [
    "Now we we have a model and evaluated it (not the most amazing stats I know...) we can do a prediction. We'll use the test data, but feel free to create your own test set!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1e8dc45a-289f-4e1b-ba03-9d1aed80eed6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    609911.312500\n",
      "1    316431.781250\n",
      "2    316130.843750\n",
      "3    315569.250000\n",
      "4    101301.218750\n",
      "5    102049.414062\n",
      "6    102607.375000\n",
      "7      4081.224609\n",
      "8      3117.708496\n",
      "9      3378.377441\n",
      "Name: amount, dtype: float32\n"
     ]
    }
   ],
   "source": [
    "y_pred = predictor.predict(test_data.drop(columns=['amount']))\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d508354e-202c-4180-aac5-d5461a9935d3",
   "metadata": {
    "tags": []
   },
   "source": [
    "Well it made some predictions, but if you compare the values it predicted to the original in the test data well..kinda meh. Let's see if we can improve this by doing something more fancy!\n",
    "\n",
    "## LLMs\n",
    "\n",
    "By now we hope we don't have to explain to you what an LLM is - but if that is the case we'd suggest you'd ask ChatGPT! \n",
    "\n",
    "Normally you'd turn to a LLM for anything related to language, however they aren't half bad at working with numbers and structured data either.\n",
    "\n",
    "### Chatting with Bison. Or is it Bisons..\n",
    "\n",
    "Let's set up a connection to our PALM2 text model - called bison-text, where bison says something about the size of the model. PALM2 is the name of the model (like GPT 1/2/3/4) that powers both Vertex AI search and conversations and for instance Bard.\n",
    "\n",
    "Because we want to know things about our transactions we will use the transactions file as the context when asking the LLM questions. This way it will know how to react and answer. To make this quick and efficient we won't just copy paste the contents of the file into a chat,\n",
    "we will use something called embeddings - this turns chunks of text into mathemetical representations which can be used to really quickly find text similar to our question - and we will send that chunk of text to the LLM.\n",
    "\n",
    "Sounds hocus pocus we know...wait till you see all the code we need :-P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6146d39e-ff59-4280-9629-b3a5cdefe009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Ignoring invalid distribution -oogle-auth (/opt/conda/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: chromadb in /opt/conda/lib/python3.10/site-packages (0.3.26)\n",
      "Requirement already satisfied: pandas>=1.3 in /opt/conda/lib/python3.10/site-packages (from chromadb) (2.1.1)\n",
      "Requirement already satisfied: requests>=2.28 in /opt/conda/lib/python3.10/site-packages (from chromadb) (2.31.0)\n",
      "Requirement already satisfied: pydantic>=1.9 in /opt/conda/lib/python3.10/site-packages (from chromadb) (1.10.8)\n",
      "Requirement already satisfied: hnswlib>=0.7 in /opt/conda/lib/python3.10/site-packages (from chromadb) (0.7.0)\n",
      "Requirement already satisfied: clickhouse-connect>=0.5.7 in /opt/conda/lib/python3.10/site-packages (from chromadb) (0.6.4)\n",
      "Requirement already satisfied: duckdb>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from chromadb) (0.8.1)\n",
      "Requirement already satisfied: fastapi>=0.85.1 in /opt/conda/lib/python3.10/site-packages (from chromadb) (0.97.0)\n",
      "Requirement already satisfied: uvicorn[standard]>=0.18.3 in /opt/conda/lib/python3.10/site-packages (from chromadb) (0.22.0)\n",
      "Requirement already satisfied: numpy>=1.21.6 in /opt/conda/lib/python3.10/site-packages (from chromadb) (1.23.5)\n",
      "Requirement already satisfied: posthog>=2.4.0 in /opt/conda/lib/python3.10/site-packages (from chromadb) (3.0.1)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /opt/conda/lib/python3.10/site-packages (from chromadb) (4.6.3)\n",
      "Requirement already satisfied: pulsar-client>=3.1.0 in /opt/conda/lib/python3.10/site-packages (from chromadb) (3.2.0)\n",
      "Requirement already satisfied: onnxruntime>=1.14.1 in /opt/conda/lib/python3.10/site-packages (from chromadb) (1.15.1)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in /opt/conda/lib/python3.10/site-packages (from chromadb) (0.13.3)\n",
      "Requirement already satisfied: tqdm>=4.65.0 in /opt/conda/lib/python3.10/site-packages (from chromadb) (4.65.0)\n",
      "Requirement already satisfied: overrides>=7.3.1 in /opt/conda/lib/python3.10/site-packages (from chromadb) (7.3.1)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from clickhouse-connect>=0.5.7->chromadb) (2023.5.7)\n",
      "Requirement already satisfied: urllib3>=1.26 in /opt/conda/lib/python3.10/site-packages (from clickhouse-connect>=0.5.7->chromadb) (1.26.16)\n",
      "Requirement already satisfied: pytz in /opt/conda/lib/python3.10/site-packages (from clickhouse-connect>=0.5.7->chromadb) (2023.3)\n",
      "Requirement already satisfied: zstandard in /opt/conda/lib/python3.10/site-packages (from clickhouse-connect>=0.5.7->chromadb) (0.19.0)\n",
      "Requirement already satisfied: lz4 in /opt/conda/lib/python3.10/site-packages (from clickhouse-connect>=0.5.7->chromadb) (4.3.2)\n",
      "Requirement already satisfied: starlette<0.28.0,>=0.27.0 in /opt/conda/lib/python3.10/site-packages (from fastapi>=0.85.1->chromadb) (0.27.0)\n",
      "Requirement already satisfied: coloredlogs in /opt/conda/lib/python3.10/site-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in /opt/conda/lib/python3.10/site-packages (from onnxruntime>=1.14.1->chromadb) (23.5.26)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from onnxruntime>=1.14.1->chromadb) (23.1)\n",
      "Requirement already satisfied: protobuf in /opt/conda/lib/python3.10/site-packages (from onnxruntime>=1.14.1->chromadb) (3.20.3)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from onnxruntime>=1.14.1->chromadb) (1.12)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.3->chromadb) (2.8.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.3->chromadb) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from posthog>=2.4.0->chromadb) (1.16.0)\n",
      "Requirement already satisfied: monotonic>=1.5 in /opt/conda/lib/python3.10/site-packages (from posthog>=2.4.0->chromadb) (1.6)\n",
      "Requirement already satisfied: backoff>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from posthog>=2.4.0->chromadb) (2.2.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.28->chromadb) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.28->chromadb) (3.4)\n",
      "Requirement already satisfied: click>=7.0 in /opt/conda/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (8.1.3)\n",
      "Requirement already satisfied: h11>=0.8 in /opt/conda/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.14.0)\n",
      "Requirement already satisfied: httptools>=0.5.0 in /opt/conda/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.5.0)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in /opt/conda/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (6.0)\n",
      "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /opt/conda/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.17.0)\n",
      "Requirement already satisfied: watchfiles>=0.13 in /opt/conda/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.19.0)\n",
      "Requirement already satisfied: websockets>=10.4 in /opt/conda/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (11.0.3)\n",
      "Requirement already satisfied: anyio<5,>=3.4.0 in /opt/conda/lib/python3.10/site-packages (from starlette<0.28.0,>=0.27.0->fastapi>=0.85.1->chromadb) (3.7.0)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /opt/conda/lib/python3.10/site-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3.4.0->starlette<0.28.0,>=0.27.0->fastapi>=0.85.1->chromadb) (1.3.0)\n",
      "Requirement already satisfied: exceptiongroup in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3.4.0->starlette<0.28.0,>=0.27.0->fastapi>=0.85.1->chromadb) (1.1.1)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -oogle-auth (/opt/conda/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#  Stuff we need to import\n",
    "# \n",
    "! pip install chromadb\n",
    "import time\n",
    "import io\n",
    "from typing import List\n",
    "from os import listdir\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "# Langchain\n",
    "import langchain\n",
    "from pydantic import BaseModel\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.document_loaders.csv_loader import CSVLoader\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "\n",
    "# Vertex AI\n",
    "from google.cloud import aiplatform\n",
    "from langchain.chat_models import ChatVertexAI\n",
    "from langchain.embeddings import VertexAIEmbeddings\n",
    "from langchain.llms import VertexAI\n",
    "from langchain.schema import HumanMessage, SystemMessage\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f269005d-762a-404b-ba4a-30ec6c48ca74",
   "metadata": {},
   "source": [
    "So now we have imported a bunch of stuff, but we aren't there yet, we need to create a little dirty work around - please just pretend you didn't see this ;-)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ec3a5ac5-6064-4dbd-bbb7-656d69eab5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stolen from: https://github.com/GoogleCloudPlatform/generative-ai/blob/main/language/examples/langchain-intro/intro_langchain_palm_api.ipynb\n",
    "#\n",
    "# Utility functions for Embeddings API with rate limiting\n",
    "def rate_limit(max_per_minute):\n",
    "    period = 60 / max_per_minute\n",
    "    print(\"Waiting\")\n",
    "    while True:\n",
    "        before = time.time()\n",
    "        yield\n",
    "        after = time.time()\n",
    "        elapsed = after - before\n",
    "        sleep_time = max(0, period - elapsed)\n",
    "        if sleep_time > 0:\n",
    "            print(\".\", end=\"\")\n",
    "            time.sleep(sleep_time)\n",
    "\n",
    "\n",
    "class CustomVertexAIEmbeddings(VertexAIEmbeddings, BaseModel):\n",
    "    requests_per_minute: int\n",
    "    num_instances_per_batch: int\n",
    "\n",
    "    # Overriding embed_documents method\n",
    "    def embed_documents(self, texts: List[str]):\n",
    "        limiter = rate_limit(self.requests_per_minute)\n",
    "        results = []\n",
    "        docs = list(texts)\n",
    "\n",
    "        while docs:\n",
    "            # Working in batches because the API accepts maximum 5\n",
    "            # documents per request to get embeddings\n",
    "            head, docs = (\n",
    "                docs[: self.num_instances_per_batch],\n",
    "                docs[self.num_instances_per_batch :],\n",
    "            )\n",
    "            chunk = self.client.get_embeddings(head)\n",
    "            results.extend(chunk)\n",
    "            next(limiter)\n",
    "\n",
    "        return [r.values for r in results]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b1aef05-5b09-4285-835c-7ed31e0da7f0",
   "metadata": {},
   "source": [
    "Now we are actually going to define the LLM and the Embedding service. Remember, we need to embeddings to feed the LLM our transactions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bdab1ff9-be76-4eff-a7af-95eb57958180",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stolen from: https://github.com/GoogleCloudPlatform/generative-ai/blob/main/language/examples/langchain-intro/intro_langchain_palm_api.ipynb\n",
    "# \n",
    "#  I increased the temp a little, haven't experimented with top k and p to much\n",
    "#\n",
    "# LLM model\n",
    "llm = VertexAI(\n",
    "    model_name=\"text-bison@001\",\n",
    "    max_output_tokens=256,\n",
    "    temperature=0.5,\n",
    "    top_p=0.8,\n",
    "    top_k=40,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "# Embedding\n",
    "EMBEDDING_QPM = 60\n",
    "EMBEDDING_NUM_BATCH = 5\n",
    "embeddings = CustomVertexAIEmbeddings(\n",
    "    requests_per_minute=EMBEDDING_QPM,\n",
    "    num_instances_per_batch=EMBEDDING_NUM_BATCH,\n",
    "    max_output_tokens=1024 # I've changed the default to allow for more output token in the embeddings (default is like 256)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b46f3029-326d-4e8d-8d99-893f4446f157",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now where would the fun be if we could just import the csv file...we load it and add each row as a seperate document\n",
    "loader = CSVLoader(file_path='train_transactions.csv', encoding=\"utf-8\", csv_args={'delimiter': ','})\n",
    "data = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "32634e53-f29f-4480-a9bc-3bc75ae55749",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting\n",
      ".........."
     ]
    }
   ],
   "source": [
    "# Store the rows in a local vectorstore as index\n",
    "# it may take a while since API is rate limited\n",
    "# Also found this somewhere, added persistence for the db\n",
    "# This takes a lotta lottta lotta time\n",
    "db = Chroma.from_documents(data, embeddings, persist_directory = \"index_bank\")\n",
    "db.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5d9c6f05-d340-436b-a11e-82682583abe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Max k as a search arguments gives us some room to experiment what works best when using embeddings. \n",
    "#\n",
    "#\n",
    "retriever = db.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 10})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b34b4fae-e3d8-40f9-a313-949acbacc89a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uses LLM to synthesize results from the search index.\n",
    "# We use Vertex PaLM Text API for LLM\n",
    "# Create three query types so be able to test the differences\n",
    "#\n",
    "qa1 = RetrievalQA.from_chain_type(\n",
    "    llm=llm, chain_type=\"stuff\", retriever=retriever\n",
    ")\n",
    "qa2 = RetrievalQA.from_chain_type(\n",
    "    llm=llm, chain_type=\"map_reduce\", retriever=retriever\n",
    ")\n",
    "qa3 = RetrievalQA.from_chain_type(\n",
    "    llm=llm, chain_type=\"refine\", retriever=retriever\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e8bd9f27-1d9c-4f07-95fb-497aa1035c4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'query': 'Based on the context can you predict the next transaction?', 'result': 'The next transaction is likely to be a transfer of 8147 from 1011226111 to 7882725911.'}\n"
     ]
    }
   ],
   "source": [
    "# I'm sure I haven't mastered the art of prompt engineering just yet, but I like this prompt for now. I only replace the question\n",
    "# at the end and pick qa1/2/3 \n",
    "query=\"Based on the context can you predict the next transaction?\"\n",
    "\n",
    "result = qa1({\"query\": query})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4d3e3e-bf8a-43a6-9726-3d9810e7c59b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m109",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m109"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
